{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fileoperations.fileoperations import getFileNamesInDir\n",
    "from symbtrdataextractor import symbtrreader, extractor\n",
    "import os\n",
    "import json\n",
    "import pandas as pd \n",
    "import numbers\n",
    "\n",
    "import pdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usuldict = json.load(open('./unittests/data/usul_extended.json','r'))\n",
    "\n",
    "symbTrfolder = '../'\n",
    "symbTrTxtfolder = os.path.join(symbTrfolder, 'txt')\n",
    "symbTrMu2Folder = os.path.join(symbTrfolder, 'mu2')\n",
    "\n",
    "symbTr_work_file = os.path.join(symbTrfolder, 'symbTr_mbid.json')\n",
    "\n",
    "txtfiles, dummy, symbtrnames = getFileNamesInDir(symbTrTxtfolder, keyword = '*.txt')\n",
    "symbtrnames = [os.path.splitext(s)[0] for s in symbtrnames]\n",
    "\n",
    "mu2files = [os.path.join(symbTrMu2Folder, sn + '.mu2') for sn in symbtrnames]\n",
    "\n",
    "symbTrTxtSavefolder = os.path.join('..', '..', 'symbtr_corrections', 'txt')\n",
    "if not os.path.exists(symbTrTxtSavefolder):\n",
    "    os.makedirs(symbTrTxtSavefolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 acem--ilahi--duyek--aldanma_dunya--zekai_dede\n",
      "1 acem--ilahi--nimevsat--calabim_bir--haci_bayram_veli\n",
      "2 acem--kupe--duyek--zulfunu--ahmet_avni_konuk\n",
      "3 acem--selam--devrikebir--asik-i_ger--huseyin_fahreddin_dede\n",
      "    179.0: men   and Ez  are in the same measure!\n",
      "    171.0: men   and Fey  are in the same measure!\n",
      "    163.0: men   and Ez  are in the same measure!\n",
      "    155.0: men   and Yâ  are in the same measure!\n",
      "    150.0: dost   and Pîr_ are in the same measure!\n",
      "    143.0: red   and Ah  are in the same measure!\n",
      "    140.0: rîz   and Her  are in the same measure!\n",
      "    137.0: red   and Ez  are in the same measure!\n",
      "    134.0: red   and Bâ are in the same measure!\n",
      "    76.0: tim   and Ah  are in the same measure!\n",
      "    3.0: men   and Ah  are in the same measure!\n",
      "acem--selam--devrikebir--asik-i_ger--huseyin_fahreddin_dede, 106, VOCAL_SECTION does not start on a measure: 3.85714285714\n",
      "acem--selam--devrikebir--asik-i_ger--huseyin_fahreddin_dede, 627, VOCAL_SECTION does not start on a measure: 76.5\n",
      "acem--selam--devrikebir--asik-i_ger--huseyin_fahreddin_dede, 914, VOCAL_SECTION does not start on a measure: 134.666666667\n",
      "acem--selam--devrikebir--asik-i_ger--huseyin_fahreddin_dede, 929, VOCAL_SECTION does not start on a measure: 137.666666667\n",
      "acem--selam--devrikebir--asik-i_ger--huseyin_fahreddin_dede, 946, VOCAL_SECTION does not start on a measure: 140.666666667\n",
      "acem--selam--devrikebir--asik-i_ger--huseyin_fahreddin_dede, 964, VOCAL_SECTION does not start on a measure: 143.5\n",
      "acem--selam--devrikebir--asik-i_ger--huseyin_fahreddin_dede, 1000, VOCAL_SECTION does not start on a measure: 150.5\n",
      "acem--selam--devrikebir--asik-i_ger--huseyin_fahreddin_dede, 1024, VOCAL_SECTION does not start on a measure: 155.666666667\n",
      "acem--selam--devrikebir--asik-i_ger--huseyin_fahreddin_dede, 1056, VOCAL_SECTION does not start on a measure: 163.666666667\n",
      "acem--selam--devrikebir--asik-i_ger--huseyin_fahreddin_dede, 1094, VOCAL_SECTION does not start on a measure: 171.666666667\n",
      "acem--selam--devrikebir--asik-i_ger--huseyin_fahreddin_dede, 1126, VOCAL_SECTION does not start on a measure: 179.666666667\n",
      "4 acem--seyir--sofyan--1--erol_bingol\n",
      "acem--seyir--sofyan--1--erol_bingol, Missing section info in lyrics.\n",
      "5 acem--seyir--sofyan--1--sefik_gurmeric\n",
      "acem--seyir--sofyan--1--sefik_gurmeric, Missing section info in lyrics.\n",
      "6 acem--turku--duyek--ordunun_dereleri--ordu\n",
      "7 acemasiran--aranagme--agiraksak--1--\n",
      "8 acemasiran--aranagme--aksak--1--\n",
      "9 acemasiran--aranagme--curcuna--1--\n",
      "10 acemasiran--aranagme--semai--1--\n",
      "11 acemasiran--aranagme--senginsemai--1--\n",
      "12 acemasiran--aranagme--sofyan--1--\n",
      "13 acemasiran--aranagme--yuruksemai--1--\n",
      "14 acemasiran--beste--devrikebir--ber_kusa-yi--basmaci_abdi_efendi\n",
      "acemasiran--beste--devrikebir--ber_kusa-yi--basmaci_abdi_efendi, Missing section info in lyrics.\n",
      "15 acemasiran--beste--zencir--hayatin_cumleye--dellalzade_haci_ismail_efendi\n",
      "acemasiran--beste--zencir--hayatin_cumleye--dellalzade_haci_ismail_efendi, Missing section info in lyrics.\n",
      "Ends prematurely!\n",
      "16 acemasiran--fantezi--yuruksemai_ii--ey_benim--resat_erer\n",
      "17 acemasiran--ilahi--muhammes--ta_dil--calakzade_mustafa_efendi\n",
      "acemasiran--ilahi--muhammes--ta_dil--calakzade_mustafa_efendi, Missing section info in lyrics.\n",
      "18 acemasiran--kupe--aksaksemai--bir--ahmet_avni_konuk\n",
      "19 acemasiran--mars--nimsofyan--korkma_sonmez--ali_rifat_cagatay\n",
      "20 acemasiran--nakis--yuruksemai--ne_hevayi--dede_efendi\n",
      "Ends prematurely!\n",
      "21 acemasiran--pesrev--devrikebir----dede_salih_efendi\n",
      "22 acemasiran--pesrev--duyek--son_pesrev--huseyin_fahreddin_dede\n",
      "acemasiran--pesrev--duyek--son_pesrev--huseyin_fahreddin_dede, Missing section info in lyrics.\n",
      "23 acemasiran--pesrev--frenkcin----nuri_halil_poyraz\n",
      "24 acemasiran--pesrev--muhammes----gazi_giray_han\n",
      "25 acemasiran--sarki--agiraksak--bir_haber--bimen_sen\n",
      "Ends prematurely!\n",
      "26 acemasiran--sarki--agiraksak--bir_teselli--serif_icli\n",
      "Ends prematurely!\n",
      "27 acemasiran--sarki--agiraksak--goncasindan_gulsenin--emin_ongan\n",
      "Ends prematurely!\n",
      "28 acemasiran--sarki--agiraksak--mahveder_her--neyzen_riza_bey\n",
      "Ends prematurely!\n",
      "29 acemasiran--sarki--agiraksak--ne_kadar--artaki_candan\n",
      "Ends prematurely!\n",
      "30 acemasiran--sarki--agirduyek--kime_halim--faize_ergin\n",
      "Ends prematurely!\n",
      "31 acemasiran--sarki--aksak--acildi_nevbahar--sadullah_aga\n",
      "32 acemasiran--sarki--aksak--dinle_sozum--iii_selim\n",
      "    34.0: hım   and Yâr_ are in the same measure!\n",
      "    28.0: hâ   and Yâr_ are in the same measure!\n",
      "    10.0: hım   and Yâr_ are in the same measure!\n",
      "    4.0: hâ   and Yâr_ are in the same measure!\n",
      "acemasiran--sarki--aksak--dinle_sozum--iii_selim, 44, VOCAL_SECTION does not start on a measure: 4.33333333333\n",
      "acemasiran--sarki--aksak--dinle_sozum--iii_selim, 97, VOCAL_SECTION does not start on a measure: 10.3333333333\n",
      "acemasiran--sarki--aksak--dinle_sozum--iii_selim, 151, ARANAGME does not start on a measure: 16.1666666667\n",
      "acemasiran--sarki--aksak--dinle_sozum--iii_selim, 202, ARANAGME does not start on a measure: 20.1666666667\n",
      "acemasiran--sarki--aksak--dinle_sozum--iii_selim, 296, VOCAL_SECTION does not start on a measure: 28.3333333333\n",
      "acemasiran--sarki--aksak--dinle_sozum--iii_selim, 349, VOCAL_SECTION does not start on a measure: 34.3333333333\n",
      "Ends prematurely!\n",
      "33 acemasiran--sarki--aksak--dustum_bir--ali_riza_avni_tinaz\n",
      "acemasiran--sarki--aksak--dustum_bir--ali_riza_avni_tinaz, Missing section info in lyrics.\n",
      "34 acemasiran--sarki--aksak--gonlum_dusuyor--ismail_baha_surelsan\n",
      "35 acemasiran--sarki--aksak--gordum_seni--irfan_dogrusoz\n",
      "Ends prematurely!\n",
      "36 acemasiran--sarki--aksak--lutfeyle_meded--dede_efendi\n",
      "37 acemasiran--sarki--aksak--o_tebessum--ismail_baha_surelsan"
     ]
    }
   ],
   "source": [
    "symbTr_work = json.load(open(symbTr_work_file, 'r'))\n",
    "\n",
    "for i, (tf, mf, sn) in enumerate(zip(txtfiles, mu2files, symbtrnames)):\n",
    "    saveTxtfile = os.path.join(symbTrTxtSavefolder, sn + '.txt')\n",
    "    if not sn[0:2] == '._':\n",
    "        print str(i) + ' ' + sn\n",
    "        \n",
    "        mu2header = symbtrreader.readMu2Header(mf)[0] \n",
    "        \n",
    "        for usul in usuldict.values():\n",
    "            for uv in usul['variants']:\n",
    "                if uv['mu2_name'] == mu2header['usul']['mu2_name']:\n",
    "                    mertebe = uv['mertebe']\n",
    "                    zaman = uv['num_pulses']\n",
    "                    break\n",
    "                    \n",
    "        df = pd.read_csv(tf, sep='\\t')\n",
    "        for index, row in df.iterrows():\n",
    "            # recompute the erroneous gracenotes with non-zero duration\n",
    "            if row['Kod'] == 8 and row['Ms'] > 0:\n",
    "                row['Pay'] = 0\n",
    "                row['Payda'] = 0\n",
    "                row['Ms'] = 0\n",
    "\n",
    "            # recompute zaman and mertebe, if we hit kod 51\n",
    "            if row['Kod'] == 51:\n",
    "                zaman = row['Pay']\n",
    "                mertebe = row['Payda']\n",
    "                offset_incr = 0\n",
    "            else:\n",
    "                # compute offset\n",
    "                offset_incr = 0 if row['Payda'] ==0 else float(row['Pay'])/row['Payda']*mertebe/zaman\n",
    "            if index == 0:\n",
    "                row['Offset'] = offset_incr\n",
    "            else:\n",
    "                prev_row = df.iloc[index-1]\n",
    "                row['Offset'] = offset_incr + prev_row['Offset']\n",
    "\n",
    "            # change null to empty string\n",
    "            for key, val in row.iteritems():\n",
    "                if pd.isnull(val):\n",
    "                    row[key] = ''\n",
    "\n",
    "            # make sure that \"Sira\" column continues consecutively\n",
    "            row['Sira'] = index+1\n",
    "\n",
    "            # reassign\n",
    "            df.iloc[index] = row\n",
    "        df.to_csv(saveTxtfile, sep='\\t', index=False)\n",
    "        \n",
    "        txtdata = extractor.extract(saveTxtfile)[0]\n",
    "        if not (round(row['Offset']*10000)*0.0001).is_integer():\n",
    "            print \"Ends prematurely!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
